{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lex3.ipynb","provenance":[],"mount_file_id":"1k66WKZJRGtrgYv0BeFUXBAGD3DahsoLK","authorship_tag":"ABX9TyNn4e5FoYWueLy3cau07ijd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"2xYMHmqbfLhA","colab_type":"code","outputId":"81c7f4f6-89b0-4984-c46b-685dea26e00e","executionInfo":{"status":"ok","timestamp":1587268176241,"user_tz":-330,"elapsed":4189,"user":{"displayName":"Pradeep Chauhan","photoUrl":"","userId":"05150516264522047115"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, InputLayer\n","import keras\n","from keras.layers import Dropout\n","\n","# Reading the data\n","train = pd.read_csv('./drive/My Drive/Datasets/house_predict.csv')\n","trainX, trainY = train.iloc[:, :train.shape[1]-1], train.iloc[:, train.shape[1]-1]\n","# There are a total of 43 categorical columns\n","categoricals = trainX.loc[:, trainX.dtypes == 'O'].columns\n","len(categoricals) # 43\n","# Preprocessing step: \n","# One Hot Encoder cannot work with NaN, hence filling NaN with mode of categorical columns\n","cat_features = trainX.loc[:, categoricals]\n","cat_features = cat_features.fillna(cat_features.mode().iloc[0, :])\n","# One hot encoding these features\n","ohe = OneHotEncoder(handle_unknown='ignore')\n","res = ohe.fit_transform(cat_features).toarray()\n","cols = np.array([])\n","for i in range(cat_features.shape[1]):\n","    cols = np.concatenate((cols, categoricals[i] + '_' + np.sort(cat_features.iloc[:, i].unique())))    \n","cat = pd.DataFrame(res, columns=cols)\n","# Total 252 categorical features\n","cat.shape # (1460, 252)\n","# Dropping original categorical variables\n","trainX = trainX.drop(categoricals, axis=1)\n","# Concatenating the One Hot Encoded variables to the train dataset\n","trainX = pd.concat([trainX, cat], axis=1)\n","# New data shape\n","trainX.shape # (1460, 289)\n","# Filling the NaN with median\n","trainX.fillna(trainX.median(), inplace=True)\n","# Normalizing training features\n","scalar = MinMaxScaler()\n","norm_train = pd.DataFrame(scalar.fit_transform(trainX), columns=trainX.columns)\n","# Normalizing training target\n","scalar_target = MinMaxScaler()\n","trainY = scalar_target.fit_transform(trainY.values.reshape(-1, 1))\n","# Defining the network\n","model = Sequential([\n","  Dense(norm_train.shape[1], input_dim=norm_train.shape[1], activation='relu'),\n","  Dropout(0.30),\n","  Dense(norm_train.shape[1], input_dim=norm_train.shape[1], activation='relu'),\n","  Dropout(0.30),\n","  Dense(norm_train.shape[1], input_dim=norm_train.shape[1], activation='relu'),\n","  Dropout(0.30),\n","  Dense(norm_train.shape[1], input_dim=norm_train.shape[1], activation='relu'),\n","  Dropout(0.30),\n","  Dense(norm_train.shape[1], input_dim=norm_train.shape[1], activation='relu'),\n","  Dropout(0.30),      \n","  # Dense(units=norm_train.shape[1]//2, activation='sigmoid'),    \n","  Dense(units=1, activation='softmax'),\n","])\n","# Printing model summary\n","model.summary()\n","# _________________________________________________________________\n","# Layer (type)                 Output Shape              Param #   \n","# =================================================================\n","# dense_34 (Dense)             (None, 289)               83810     \n","# _________________________________________________________________\n","# dense_35 (Dense)             (None, 144)               41760     \n","# _________________________________________________________________\n","# dense_36 (Dense)             (None, 1)                 145       \n","# =================================================================\n","# Total params: 125,715\n","# Trainable params: 125,715\n","# Non-trainable params: 0\n","# Compiling and Training Network\n","model.compile(optimizer='sgd', loss='mean_squared_error')\n","model.fit(trainX, trainY, batch_size=512, epochs=21, verbose=1, validation_split=0.2)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_4 (Dense)              (None, 289)               83810     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 289)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 289)               83810     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 289)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 289)               83810     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 289)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 289)               83810     \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 289)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 289)               83810     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 289)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 290       \n","=================================================================\n","Total params: 419,340\n","Trainable params: 419,340\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1168 samples, validate on 292 samples\n","Epoch 1/21\n","1168/1168 [==============================] - 0s 271us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 2/21\n","1168/1168 [==============================] - 0s 93us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 3/21\n","1168/1168 [==============================] - 0s 92us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 4/21\n","1168/1168 [==============================] - 0s 101us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 5/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 6/21\n","1168/1168 [==============================] - 0s 92us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 7/21\n","1168/1168 [==============================] - 0s 93us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 8/21\n","1168/1168 [==============================] - 0s 92us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 9/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 10/21\n","1168/1168 [==============================] - 0s 93us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 11/21\n","1168/1168 [==============================] - 0s 91us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 12/21\n","1168/1168 [==============================] - 0s 88us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 13/21\n","1168/1168 [==============================] - 0s 108us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 14/21\n","1168/1168 [==============================] - 0s 95us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 15/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 16/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 17/21\n","1168/1168 [==============================] - 0s 98us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 18/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 19/21\n","1168/1168 [==============================] - 0s 90us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 20/21\n","1168/1168 [==============================] - 0s 96us/step - loss: 0.6483 - val_loss: 0.6456\n","Epoch 21/21\n","1168/1168 [==============================] - 0s 93us/step - loss: 0.6483 - val_loss: 0.6456\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f7fe0eb7da0>"]},"metadata":{"tags":[]},"execution_count":2}]}]}